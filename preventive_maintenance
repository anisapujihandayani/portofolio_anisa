# -*- coding: utf-8 -*-
"""prediction system preventive maintenance stamping machine

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jWh5DgA-8Ko00RSAIFvXsXbNYvgQQw6i
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt
from sklearn.svm import SVR
from datetime import timedelta
from sklearn.model_selection import GridSearchCV

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

data = pd.read_csv("data_new.csv")

data.head()

data.describe()

data.drop(columns=["part", "proses", "hasil produksi", "keterangan", "waktu produksi"], inplace=True)
data.dropna(inplace=True)
data

from sklearn.preprocessing import LabelEncoder
data['GP_new'] = LabelEncoder().fit_transform(data['GP'])
data

data.drop(columns=["GP"], inplace=True)
data.dropna(inplace=True)

data["tanggal"]=pd.to_datetime(data["tanggal"])

data

data['B'] = data['B'].astype('int')

datewise=data.groupby(["tanggal"]).agg({"A":'sum',"B":'sum',"C":'sum',"D":'sum',"E":'sum',"F":'sum',"waktu mesin":'sum'})

from sklearn.preprocessing import LabelEncoder
data['tanggal_new'] = LabelEncoder().fit_transform(data['tanggal'])
data

data.drop(columns=["tanggal"], inplace=True)
data.dropna(inplace=True)

datewise_new=data.groupby(["tanggal_new"]).agg({"A":'sum',"B":'sum',"C":'sum',"D":'sum',"E":'sum',"F":'sum',"waktu mesin":'sum'})

datewise_new

datewise_new["rusak"]=datewise_new["C"]+datewise_new["D"]

print(datewise_new)

datewise_new

from sklearn.model_selection import train_test_split

x = datewise_new.drop(['waktu mesin'], axis = 1).copy()
y = datewise_new['waktu mesin'].copy()
x.shape, y.shape

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

x

y

from sklearn.svm import SVR

from sklearn import svm

model = svm.SVR()

model.fit(x_train, y_train)

model.fit([[  0],
       [  1],
       [ 32],
       [ 60],
       [ 90],
       [ 91],
       [120],
       [121],
       [151],
       [173],
       [174],
       [181],
       [187],
       [188],
       [189],
       [192],
       [193],
       [194],
       [196],
       [199],
       [200],
       [201],
       [202],
       [203],
       [212],
       [213],
       [220],
       [221],
       [222],
       [223],
       [224],
       [227],
       [228],
       [229],
       [230],
       [231],
       [234],
       [235],
       [236],
       [244],
       [274],
       [304],
       [305],
       [334],
       [335]], [[  0],
       [  1],
       [ 32],
       [ 60],
       [ 90],
       [ 91],
       [120],
       [121],
       [151],
       [173],
       [174],
       [181],
       [187],
       [188],
       [189],
       [192],
       [193],
       [194],
       [196],
       [199],
       [200],
       [201],
       [202],
       [203],
       [212],
       [213],
       [220],
       [221],
       [222],
       [223],
       [224],
       [227],
       [228],
       [229],
       [230],
       [231],
       [234],
       [235],
       [236],
       [244],
       [274],
       [304],
       [305],
       [334],
       [335]])

train_ml=datewise_new.iloc[:int(datewise.shape[0]*0.70)]
valid_ml=datewise_new.iloc[int(datewise.shape[0]*0.70):]
model_scores=[]

datewise["Days Since"]=datewise.index-datewise.index[0]
datewise["Days Since"]=datewise["Days Since"].dt.days

train_ml

valid_ml



svm=SVR(C=1,degree=6,kernel='poly',epsilon=0.01)

score = model.score(x_test, y_test)

print("Akurasi model: ", score)

y_pred = model.predict(x_test)

from sklearn.metrics import mean_squared_error,r2_score

model_scores=[]
